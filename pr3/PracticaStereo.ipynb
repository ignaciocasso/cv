{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de reconstrucción.  Parte II. Visión estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignacio Casso y Diego Pérez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visión Computacional 2018-19 <br>\n",
    "Practica 2. 29 de octubre de 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este enunciado está en el archivo \"PracticaStereo.ipynb\" o su versión \"pdf\" que puedes encontrar en el Aula Virtual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos de esta práctica son:\n",
    "* reconstruir puntos de una escena a partir de una serie de correspondencias manuales entre dos imágenes calibradas;\n",
    "* determinar la geometría epipolar de un par de cámaras a partir de sus matrices de proyección;\n",
    "* implementar la búsqueda automática de correspondencias que use las restricciones impuestas por la geometría epipolar, aplicando para ello métodos de cortes de grafos;\n",
    "* realizar una reconstrucción densa de la escena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica es necesario disponer del siguiente software:\n",
    "* Python 2.7 ó 3.X \n",
    "* Jupyter http://jupyter.org/.\n",
    "* Las librerías científicas de Python: NumPy, SciPy, y Matplotlib.\n",
    "* La librería OpenCV\n",
    "* La librería PyMaxFlow\n",
    "\n",
    "El material necesario para la práctica se puede descargar del Aula Virtual en la carpeta ``MaterialesPractica`` del tema de visión estéreo. Esta\n",
    "carpeta contiene:\n",
    "* Una serie de pares estéreo en el directorio images;\n",
    "el sufijo del fichero indica si corresponde a la cámara\n",
    "izquierda (_left) o a la derecha (_right). Bajo el\n",
    "directorio ``rectif`` se encuentran varios pares estéreo\n",
    "rectificados.\n",
    "* Un conjunto de funciones auxiliares de ``Python`` en \n",
    "el módulo ``misc.py``. La descripción de las funciones\n",
    "puede consultarse con el comando help o leyendo\n",
    "su código fuente.\n",
    "* El archivo ``cameras.npz`` con las matrices de proyección del par de cámaras con el que se tomaron todas las imágenes con prefijo minoru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La fecha límite de entrega será el martes 4 de diciembre a las 23:55.\n",
    "* La entrega consiste en dos archivos con el código, resultados y respuestas a los ejercicios:\n",
    "  1. Un \"notebook\" de Jupyter con los resultados. Las respuestas a los ejercicios debes introducirlas en tantas celdas de código o texto como creas necesarias, insertadas inmediatamente después de  un enuciado y antes del siguiente.\n",
    "  2. Un documento \"pdf\" generado a partir del fuente de Jupyter, por ejemplo usando el comando ``jupyter nbconvert --execute --to pdf notebook.ipynb``, o simplemente imprimiendo el \"notebook\" desde el navegador en la opción del menú \"File->Print preview\". Asegúrate de que el documento \"pdf\" contiene todos los resultados correctamente ejecutados.\n",
    "* Esta práctica puede realizarse en parejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los problemas de visión estéreo se supondrá la existencia de un par de cámaras calibradas cuyas matrices de proyección $\\mathbf{P}_i$ vienen dadas\n",
    "por $$\\mathbf{P}_1 = \\mathbf{K}_1\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_1 & \\mathbf{t}_1\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix},$$ $$\\mathbf{P}_2 = \\mathbf{K}_2\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_2 & \\mathbf{t}_2\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix}.$$\n",
    "    \n",
    "En esta práctica se usarán las matrices de proyección de\n",
    "dos cámaras para determinar la posición tridimensional\n",
    "de puntos de una escena. Esto es posible siempre que se\n",
    "conozcan las proyecciones de cada punto en ambas cámaras. Desafortunadamente, esta información no suele estar\n",
    "disponible y para obtenerla es preciso emplear el contenido\n",
    "de las imágenes (sus píxeles) en un proceso de búsqueda\n",
    "conocido como puesta en correspondencia. Conocer las matrices de proyección de las cámaras permite acotar el área\n",
    "de búsqueda gracias a las restricciones que proporciona la\n",
    "geometría epipolar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to show results in a window\n",
    "%matplotlib tk\n",
    "import numpy as np\n",
    "import scipy.misc as scpm\n",
    "import scipy.ndimage as scnd\n",
    "import matplotlib.pyplot as ppl\n",
    "import numpy.linalg as npla\n",
    "import maxflow.fastmin\n",
    "import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reconstrucción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo un conjunto de correspondencias entre dos\n",
    "imágenes, con matrices de calibración $P_i$ conocidas, es\n",
    "posible llevar a cabo una reconstrucción tridimensional de\n",
    "dichos puntos. En el fichero ``cameras.npz`` se encuentran\n",
    "las matrices de proyección para las dos cámaras. Para cargar\n",
    "este fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = np.load(\"cameras.npz\")\n",
    "P1 = cameras[\"left\"]\n",
    "P2 = cameras[\"right\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las imágenes con el prefijo minoru comparten este par de matrices de proyección.\n",
    "\n",
    "Leemos las imágenes y marcammos al menos seis puntos correspondientes en cada una de ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = ppl.imread(\"images/minoru_cube3_left.jpg\")\n",
    "img2 = ppl.imread(\"images/minoru_cube3_right.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-7773572c70d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maskpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ignacio/Desktop/cv/pr3/misc.py\u001b[0m in \u001b[0;36maskpoints\u001b[0;34m(image1, image2)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0mnum_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0mpoints1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0mpoints2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "pt1, pt2 = misc.askpoints(img1,img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1.** Implementa la función ``M = reconstruct(points1, points2, P1, P2)``\n",
    "que, dados una serie de N puntos 2D ``points1`` de la primera imagen y sus \n",
    "N homólogos ``points2`` de la segunda imagen\n",
    "(ambos en coordenadas homogéneas, 3 x N), y el par de matrices\n",
    "de proyección P1 y P2 de la primera y la segunda cámara\n",
    "respectivamente, calcule la reconstrucción tridimensional\n",
    "de cada punto. De ese modo, si ``points1`` y\n",
    "``points2`` son 3 × N , la matriz resultante M debe ser 4 × N.\n",
    "\n",
    "El tipo de reconstrucción debe ser algebraico, no geométrico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución**: Dado un punto $(x,y,z)$ en la escena que se proyecta en un punto $(i,j)$ de la imagen, y sea P la matriz de proyección, entonce se cumple la ecuación $(\\lambda j, \\lambda i, \\lambda)^T = P \\cdot (x,y,z,1)^T$. Si denotamos $P_r$ la r-ésima fila de la matriz P, de esa ecuación se derivan las ecuaciones lineales\n",
    "\n",
    "$0 = \\lambda j - \\lambda j = P_1 \\cdot (x,y,z,1)^T - P_3 \\cdot j \\cdot (x,y,z,1)^T = (P_1 - j \\cdot P_3) \\cdot (x,y,z,1)^T$\n",
    "\n",
    "$0 = \\lambda i - \\lambda i = P_2 \\cdot (x,y,z,1)^T - P_3 \\cdot i \\cdot (x,y,z,1)^T = (P_2 - i \\cdot P_3) \\cdot (x,y,z,1)^T$\n",
    "\n",
    "En el caso de una cámara esas dos ecuaciones lineales con 3 incógnitas nos permiten encontrar la recta de la escena que se proyecta en ese punto de la imagen. En el caso de tener dos cámaras, nos permiten encontrar un punto en la escena sabiendo los puntos donde se proyecta en cada imagen, resolviendo el sistema de 4 ecuaciones lineales y 3 incógnitas obtenido de juntar los dos pares de ecuaciones de cada cámara. Ese sistema en teoría debería ser compatible, pero los errores de calibración harán que probablemente no lo sea. Por lo tanto hay que usar métodos no exactos para resolverlo, como por ejemplo ... **TODO:** nombre del método\n",
    "\n",
    "Si consideramos el punto en la escena en coordenadas homogéneas, como indica el enunciado, tendríamos las mismas ecuaciones pero usando $\\mu \\cdot (x,y,z,1)$ en vez de $(x,y,z,1)$, lo que daría lugar a un sistema no lineal, que se podría expresar como un sistema lineal homogéneo de 4 ecuaciones y 4 incognitas pero del que se espera una recta como solución. Por las complicaciones que esto supone trabajaremos con coordenadas cartesianas y luego pasaremos la solución a coordenadas homogéneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hom_to_car(points_hom):\n",
    "    # points_hom.shape =(3,N), (4,N) ...\n",
    "    return points_hom[0:-1,:]/points_hom[-1]\n",
    "    # returned shape also (_,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(points1, points2, P1, P2):\n",
    "    # pointsx.shape = (3,N)\n",
    "\n",
    "    \"\"\"Reconstruct a set of points projected on two images.\"\"\"\n",
    "    \n",
    "    # Transform homog to cartesian co-ordinates\n",
    "    points1_car = hom_to_car(points1).transpose()\n",
    "    points2_car = hom_to_car(points2).transpose()\n",
    "\n",
    "    # build coefficient matrix and compute reconstruction by least-squares.    \n",
    "    \n",
    "    def reconstruct_(point1,point2,P1,P2):\n",
    "    \n",
    "        coeffs = np.array([\n",
    "                P1[0]-P1[2]*point1[0],\n",
    "                P1[1]-P1[2]*point1[1],\n",
    "                P2[0]-P2[2]*point2[0],\n",
    "                P2[1]-P2[2]*point2[1],\n",
    "            ])\n",
    "\n",
    "        A = coeffs[:,:-1]\n",
    "        b = - coeffs[:,-1]\n",
    "        \n",
    "        # hom\n",
    "        # A = coeffs\n",
    "        # b = np.zeros(4).reshape((4,1))\n",
    "        \n",
    "        sol,_,_,_ = npla.lstsq(A,b)\n",
    "        \n",
    "        return np.append(sol,1)\n",
    "        \n",
    "    return np.array([reconstruct_(p1,p2,P1,P2) for p1,p2 in zip(points1_car,points2_car)]).transpose()\n",
    "    # shape returned also (4,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruye los puntos marcados y pinta su estructura 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:28: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.axes3d.Axes3D at 0x7fcefea6a978>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct\n",
    "mM=reconstruct(pt1, pt2, P1, P2)\n",
    "\n",
    "# convert from homog to cartesian\n",
    "mM_car = hom_to_car(mM)\n",
    "\n",
    "# plot 3D\n",
    "# %matplotlib inline\n",
    "misc.plot3D(mM_car[0,:],mM_car[1,:],mM_car[2,:])\n",
    "# TODO: show image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2.**  Reproyecta los resultados de la reconstrucción\n",
    "en las dos cámaras y dibuja las proyecciones sobre las\n",
    "imágenes originales. Pinta también en otro color los puntos seleccionados manualmente. Comprueba si las proyecciones coinciden con los puntos marcados a mano. Comenta los resultados.\n",
    "Para dibujar los puntos puedes usar la función plothom\n",
    "de la práctica anterior o la versión que se distribuye con esta\n",
    "práctica (misc.plothom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyecto los puntos en ambas cámaras\n",
    "proy1 = P1.dot(mM)\n",
    "proy2 = P2.dot(mM)\n",
    "\n",
    "# Pinto con misc.plothom()\n",
    "ppl.figure()\n",
    "misc.plothom(proy1,'r.')\n",
    "ppl.imshow(img1)\n",
    "ppl.show()\n",
    "\n",
    "ppl.figure()\n",
    "misc.plothom(proy2,'r.')\n",
    "ppl.imshow(img2)\n",
    "ppl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometría epipolar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La geometría epipolar deriva de las relaciones que aparecen en las proyecciones de una escena sobre un par de\n",
    "cámaras. La matriz fundamental $\\mathbf{F}$, que depende exclusivamente de la configuración de las cámaras y no de la escena\n",
    "que éstas observan, es la representación algebráica de dicha\n",
    "geometría: a partir de ella se pueden calcular los epipolos\n",
    "y las líneas epipolares. La relación entre un par de cámaras\n",
    "$\\mathbf{P}_1$, $\\mathbf{P}_2$ y la matriz fundamental es de n -a- 1 (salvo factor de\n",
    "escala). Es decir, dadas dos cámaras calibradas, sólo tienen\n",
    "una matriz fundamental (excepto un factor de escala); dada\n",
    "una matriz fundamental existen infinitas configuraciones de\n",
    "cámaras posibles asociadas a ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Estimación de la matriz fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3.** Implementa la función ``F = projmat2f(P1, P2)``\n",
    "que, dadas dos matrices de proyección, calcule la matriz\n",
    "fundamental asociada a las mismas. $\\mathbf{F}$ debe ser tal que,\n",
    "si $m_1$ de la imagen 1 y $m_2$ de la imagen 2 están en\n",
    "correspondencia, entonces $m_2^\\top F m_1 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:**\n",
    "\n",
    "Si expresamos la matriz de proyección P_i como\n",
    "$P_i = K_i\\cdot\\begin{bmatrix}I & 0\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        R_i & t_i\\\\ 0^T & 1\n",
    "    \\end{bmatrix} = [ A_i | b_i ]$ y suponemos que un punto $M$ se proyecta en cada cámara en los puntos $m_i$, tenemos que:\n",
    "    \n",
    "- $- A_i^{-1} \\cdot b_i = - (K_i \\cdot R_i)^{-1} \\cdot (K_i \\cdot t_i) = - R_i^{-1} \\cdot t_i$ es el centro $C_i$ de la cámara $i$, ya que $R_i \\cdot C_i + t_i = 0$ (origen de coordenadas en el modelo intrínsico).\n",
    "\n",
    "- $A_i^{-1} \\cdot m_i$ es un vector director de la recta $R_i$ que une $C_i$ y $M$, es decir la recta que se proyecta en $m_i$, ya que $\\lambda \\begin{bmatrix}\n",
    "        m_i\\\\ 1\n",
    "    \\end{bmatrix} = P \\cdot \\begin{bmatrix}\n",
    "        X\\\\ 1\n",
    "    \\end{bmatrix} \\implies \\lambda \\begin{bmatrix}\n",
    "        m_i\\\\ 1\n",
    "    \\end{bmatrix} = A_i \\cdot X + b_i \\implies X = \\lambda \\cdot A_i^{-1} \\cdot m_i - A_i^{-1} \\cdot b_i$\n",
    "- $ u \\cdot (v \\times w)$ (producto triple de u,v,w) $= 0$, donde $u = (A_2^{-1} \\cdot m_2)^T, ~ w = A_1^{-1} \\cdot m_1$ son vectores directores de $R_2,R_1$ respectivamente, y $v = A_2^{-1} \\cdot b_2 - A_1^{-1} \\cdot b_1$ es el vector $C_1-C_2$, ya que los tres vectores son coplanares\n",
    "\n",
    "De todo esto se deriva la ecuación $[m_2^T \\cdot (A_2^{-1})^T] \\cdot ([A_2^{-1} \\cdot b_2 - A_1^{-1} \\cdot b_1] \\times [A_1^{-1} \\cdot m_1]) = (m_2^T \\cdot (A_2^{-1})^T) \\cdot Q \\cdot (A_1^{-1} \\cdot m_1) = m_2^T \\cdot F \\cdot m_1 = 0$, donde $Q = [A_2^{-1} \\cdot b_2 - A_1^{-1} \\cdot b_1]_{\\times}$ y $F = (A_2^{-1})^T \\cdot Q \\cdot A_1^{-1}$, siendo $[v]_{\\times}$ la matriz que permite expresar el producto vectorial $v \\times w$ como multiplicación matricial $[v]_{\\times} \\cdot w$. Si $v = (v_1,v_2,v_3)$, esta matriz es $[v]_{\\times} = \\begin{bmatrix}\n",
    "        0 & -v_3 & v_2\\\\ v3 & 0 & -v_1\\\\ -v_2 & v_1 & 0\n",
    "    \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projmat2f(P1,P2):\n",
    "    \"\"\" Calcula la matriz fundamental a partir de dos de proyeccion\"\"\"\n",
    "    \n",
    "    invA1= npla.inv(P1[:,0:3])\n",
    "    b1 = P1[:,3]\n",
    "    \n",
    "    invA2= npla.inv(P2[:,0:3])\n",
    "    b2 = P2[:,3]\n",
    "\n",
    "    w = invA2.dot(b2) - invA1.dot(b1)\n",
    "    Q = misc.skew(w)\n",
    "    \n",
    "    return invA2.transpose().dot(Q).dot(invA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute Fundamental matrix\n",
    "F = projmat2f(P1, P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4** ¿Cómo es la matriz fundamental de dos cámaras\n",
    "que comparten el mismo centro? (Por ejemplo, dos cámaras\n",
    "que se diferencian sólo por una rotación.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se hasta que punto tiene sentido hablar de geometría epipolar cuando dos cámaras tienen el mismo centro, ya que no existen los planos ni líneas epipolares, o más bien los planos epipolares pasan a ser rectas, y las líneas puntos.\n",
    "\n",
    "Si se define la matriz fundamental como la resultante de la fórmula derivada en el ejercicio anterior, entonces la matriz fundamental es nula, ya que el vector $C_1-C_2$ lo es.\n",
    "\n",
    "Si se define la matriz fundamental simplemente como la matriz que cumple la ecuación $m_2^\\top F m_1 = 0$ si y sólo si $m_1$ y $m_2$ están en correspondencia, entonces no existe. Esto es así porque fijando uno de los dos puntos, sea cual sea la matriz, la solución a esa ecuación es un espacio de dimensión 2 o 3 (el plano perpendicular al vector $m_2^TF$ o $Fm_1$ resultante, o todo $\\mathbb{R}^3$ si el vector es nulo), pero debería ser uno de dimensión 1, correspondiente al punto en la otra imagen en coordenadas homogéneas.\n",
    "\n",
    "Si se define como una matriz que cumple $m_2^\\top F m_1 = 0$ si $m_1$ y $m_2$ están en correspondencia, entonces no es única. Esto es así porque ahora $A_1^{-1} \\cdot m_1$ y $A_2^{-1} \\cdot m_2$ son paralelos, y la fórmula del ejercicio anterior se cumple ahora para cualquier vector, no sólo $C_1 - C_2$. Para cada vector escogido, la fórmula dará lugar a una matriz, y no todas serán iguales (de hecho es trivial ver que todas son distintas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Comprobación de F (OPCIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes dos ejercicios vamos a comprobar que la matriz F estimada a partir de P1 y P2 es correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5.** Comprueba que F es la matriz fundamental asociada a las cámaras ``P1`` y ``P2``. Para ello puedes utilizar el resultado 9.12, que aparece en la página 255 del libro Hartley, Zisserman. \"Multipe View Geometry in Computer Vision.\" (sedond edition). Cambridge University Press, 2003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede comprobar geométricamente la bondad de una matriz F, si  las epipolares con ella estimadas pasan por el homólogo de un punto dado en una de las imágenes.\n",
    "\n",
    "Dada la matriz fundamental $\\mathbf{F}$ entre las cámaras 1 y 2,\n",
    "se puede determinar, para un determinado punto $m_1$ en la\n",
    "imagen de la cámara 1, cuál es la recta epipolar $l_2$ donde se\n",
    "encontrará su homólogo en la cámara 2: $$l_2 = \\mathbf{F} m_1.$$\n",
    "\n",
    "Las siguientes dos funciones sirven para comprobar esta\n",
    "propiedad. En primer lugar, se necesita una función que\n",
    "dibuje rectas expresadas en coordenadas homogéneas, es\n",
    "decir, la versión de plothom para rectas en lugar de puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6.** Implementa la función ``plothline(line)``\n",
    "que, dada una línea expresada en coordenadas homogéneas,\n",
    "la dibuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plothline(line, axes = None):\n",
    "    \"\"\"Plot a line given its homogeneous coordinates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    line : array_like\n",
    "        Homogeneous coordinates of the line.\n",
    "    axes : AxesSubplot\n",
    "        Axes where the line should be plotted. If not given,\n",
    "        line will be plotted in the active axis.\n",
    "    \"\"\"\n",
    "    if axes == None:\n",
    "        axes = ppl.gca()\n",
    "    \n",
    "    [x0, x1, y0, y1] = axes.axis()\n",
    "\n",
    "    #     (x0, y0) ._____________________. (x1, y0)\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #     (x0, y1) .---------------------. (x1, y1)\n",
    " \n",
    "    # TODO: Compute the intersection of the line with the image\n",
    "    # borders.\n",
    "\n",
    "        \n",
    "    # TODO: Plot the line with axes.plot.\n",
    "    #axes.plot(...)\n",
    "    plotline = axes.plot(... , 'r-')\n",
    "    \n",
    "    axes.axis([x0, x1, y0, y1])\n",
    "    return plotline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7.** Completa la función ``plot_epipolar_lines(image1, image2, F)``\n",
    "que, dadas dos imágenes y la matriz fundamental que\n",
    "las relaciona, pide al usuario puntos en la imagen 1 y\n",
    "dibuje sus correspondientes epipolares en la imagen 2 usando ``plothline``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epipolar_lines(image1, image2, F):\n",
    "    \"\"\"Ask for points in one image and draw the epipolar lines for those points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1 : array_like\n",
    "        First image.\n",
    "    image2 : array_like\n",
    "        Second image.\n",
    "    F : array_like\n",
    "        3x3 fundamental matrix from image1 to image2.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.hstack([np.array(point[0]), 1])\n",
    "        ax1.plot(point[0], point[1], '.r')\n",
    "        \n",
    "        # TODO: Determine the epipolar line.\n",
    "        line = \n",
    "        \n",
    "        # Plot the epipolar line with plothline (the parameter 'axes' should be ax2).\n",
    "        plothline(line, axes=ax2)\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza esta función con un par de imágenes llamándola\n",
    "de dos formas diferentes: seleccionando puntos en la imagen\n",
    "izquierda y dibujando las epipolares en la imagen derecha\n",
    "y viceversa. Comprueba en ambos casos que las epipolares\n",
    "siempre pasan por el punto de la segunda imagen correspondiente al seleccionado en la primera. Esto confirmara la corrección de la matriz F.\n",
    "\n",
    "Añade dos figuras una que muestre la selección de puntos en\n",
    "la imagen izquierda y las rectas correspondientes en la\n",
    "imagen derecha, y otra que lo haga al revés. Indica para\n",
    "ambos casos qué matriz fundamental has usado al llamar a\n",
    "``plot_epipolar_lines``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_epipolar_lines( ... TODO ... ) #! img1,img2,F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epipolar_lines(... TODO ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Rectificación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es recomendable trabajar a partir de ahora con imágenes\n",
    "en blanco y negro y con valores reales entre 0 y 1 para cada\n",
    "uno de sus píxeles. Eso se puede conseguir con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = misc.rgb2gray(img1/255.0)\n",
    "img2 = misc.rgb2gray(img2/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de algoritmos de puesta en correspondencia,\n",
    "incluyendo el que se va a implementar en esta práctica,\n",
    "requieren que las imágenes de entrada estén rectificadas.\n",
    "\n",
    "Dos imágenes están rectificadas si sus correspondientes epipolares están alineadas horizontalmente. La rectificación de\n",
    "imágenes facilita enormemente los algoritmos de puesta en\n",
    "correspondencia, que pasan de ser problemas de búsqueda\n",
    "bidimensional a problemas de búsqueda unidimensional\n",
    "sobre filas de píxeles de las imágenes. En el material de\n",
    "la práctica se han incluido dos funciones que rectifican\n",
    "(mediante un método lineal) dos imágenes. La función\n",
    "``H1, H2 = misc.projmat2rectify(P1, P2, imsize)``\n",
    "devuelve, dadas las dos matrices de proyección y el tamaño de las imágenes en formato (filas,columnas), las\n",
    "homografías que rectifican, respectivamente, la imagen 1\n",
    "y la imagen 2. La función ``projmat2rectify`` hace uso\n",
    "de ``projmat2f``, por lo que\n",
    "es necesario que esta función esté disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 8.** Se tienen dos imágenes no rectificadas ``im1`` e\n",
    "``im2``, y su matriz fundamental asociada $\\mathbf{F}$ . Con el procedimiento explicado, se encuentran un par de homografías $\\mathbf{H}_1$ y $\\mathbf{H}_2$ que dan lugar a las imágenes rectificadas ``O1`` y ``O2``. ¿Cuál es la matriz fundamental $\\mathbf{F}′$ asociada a estas dos imágenes? ¿Por qué?\n",
    "\n",
    "Nota: F ′ depende exclusivamente de F , H1 y H2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución.**\n",
    "\n",
    "Denotamos $H_1$ y $H_2$ a las matrices de las homografías $\\mathbf{H}_1$ y $\\mathbf{H}_2$.\n",
    "\n",
    "La matriz fundamental asociada a las imágenes rectificadas sería $F' = (H_2^{-1})^T \\cdot \\mathbf{F} \\cdot H_1^{-1}$. Para probarlo basta con demostrar que dados dos puntos cualesquiera $m_1',m_2'$ en las imágenes 01,02, $~~ m_2'^T \\cdot F' \\cdot m_1' = 0$ si y sólo si $m_1',m_2'$ están en correspondencia, ya que la matriz fundamental es la única que cumple esta propiedad. Pero eso siempre es así, ya que esos puntos se corresponden con los puntos $m_1 = H_1^{-1} \\cdot m_1', m_2 = H_2^{-2} \\cdot m_2'$ en las imágenes originales, y entonces $m_2'^T \\cdot F' \\cdot m_1' = 0 \\iff m_2'^T \\cdot (H_2^{-1})^T \\cdot \\mathbf{F} \\cdot H_1^{-1} \\cdot m_1' = 0 \\iff m_2^T \\cdot F \\cdot m_1 = 0 \\iff m_1,m_2$ están en correspondencia $ \\iff m_1', m_2'$ están en correspondencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 9.** Rectifica el par de imágenes estéreo ``img1`` e ``img2`` y calcula\n",
    "la matriz fundamental asociada a estas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1, H2 = misc.projmat2rectify(P1,P2,projmat2f,img1.shape)\n",
    "O1, O2 = misc.rectify_images(img1,img2,H1,H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe60ae9b978>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.imshow(O1)\n",
    "ppl.figure()\n",
    "ppl.imshow(O2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 10. (opcional)** Calcula y muestra la matriz fundamental de las imágenes\n",
    "rectificadas. Justifica el resultado obtenido (mira la sección 9.3.1 del libro de Hartley y Zisserman, pág. 248 y 249)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr=\n",
    "Fr=Fr/Fr[2,1]\n",
    "Fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 11. (Opcional)** Usa ``plot_epipolar_lines`` para dibujar varias líneas epiplares de las imágenes rectificadas. Muestra los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epipolar_lines(... TODO ...) #! O1, O22, Fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Búsqueda de correspondencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de correspondencias consigue establecer automáticamente las correspondencias de puntos entre dos\n",
    "imágenes (lo que se ha hecho manualmente en el ejercicio 2)\n",
    "haciendo uso de las restricciones que proporciona la geometría epipolar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Cálculo de las medidas de similaridad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez rectificadas las dos imágenes de un par estéreo,\n",
    "se pueden buscar las correspondencias. Una matriz de disparidades $\\mathbf{S}$ indica, para cada píxel de la imagen 1\n",
    "rectificada, a cuántos píxeles de diferencia está su correspondencia\n",
    "en la imagen 2 rectificada. En nuestra práctica, para simplificar el problema, vamos a considerar que los elementos\n",
    "de $\\mathbf{S}$ son enteros. Para el píxel en la posición $(x, y)$ en la\n",
    "imagen 1, su correspondiente está en $(x + S[y, x], y)$ en la\n",
    "imagen 2. Si $S[y, x] < 0$, la correspondencia está hacia la\n",
    "izquierda; si $S[y, x] > 0$, la correspondencia está hacia la\n",
    "derecha; si $S[y, x] = 0$, las coordenadas de los dos puntos\n",
    "coinciden en ambas imágenes.\n",
    "\n",
    "La búsqueda de correspondencias requiere ser capaz de\n",
    "determinar el parecido visual entre píxeles de dos imágenes.\n",
    "Si los píxeles $m_1$ y $m_2$ son visualmente parecidos, tienen\n",
    "más probabilidad de estar en correspondencia que otros\n",
    "que sean visualmente diferentes. Como la\n",
    "apariencia (el nivel de gris) de un único píxel es propensa\n",
    "al ruido y poco discriminativa, el elemento de puesta en\n",
    "correspondencia será una ventana centrada en el píxel.\n",
    "Dado un píxel $m$ de una imagen, llamaremos vecindad\n",
    "del píxel de radio $K$ al conjunto de píxeles de la imagen que se encuentren dentro de una ventana de tamaño\n",
    "$(2K + 1) × (2K + 1)$ píxeles centrada en $m$ . El número de\n",
    "píxeles de una vecindad de radio $K$ es $N = (2K + 1)^2$.\n",
    "Dadas dos vecindades $w_1$ y $w_2$ de dos píxeles, el parecido\n",
    "visual entre ellas puede calcularse con la suma de *diferencias\n",
    "al cuadrado (SSD)* de cada una de sus componentes\n",
    "$$d_{SSD}(\\mathbf{v}, \\mathbf{w}) = \\sum_{i=1}^N(\\mathbf{v}_i - \\mathbf{w}_i)^2.$$\n",
    "\n",
    "La distancia $d_{SSD}$ es siempre positiva, es pequeña cuando\n",
    "dos ventanas son visualmente parecidas y grande en caso\n",
    "contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 12.** Implementa la función\n",
    "``C = localssd(im1, im2, K)``\n",
    "que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de radio K de la imagen 1 y la imagen 2. El\n",
    "resultado debe ser una matriz del mismo tamaño que las\n",
    "imágenes de entrada que contenga en cada punto el valor\n",
    "de $d_{SSD}$ para la ventana de la imagen 1 y la ventana\n",
    "de la imagen 2 centradas en él. Es decir, $C[i,j]$ debe\n",
    "ser el resultado de $d_{SSD}$ para las ventanas centradas en\n",
    "$im1[i,j]$ e $im2[i,j]$.\n",
    "\n",
    "Para este ejercicio puede resultar útil la función\n",
    "``scipy.ndimage.convolve``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import convolve\n",
    "\n",
    "def localssd(im1, im2, K):\n",
    "    \"\"\"\n",
    "    The local sum of squared differences between windows of two images.\n",
    "    \n",
    "    The size of each window is (2K+1)x(2K+1).\n",
    "    \"\"\"\n",
    "    diffs = im1 - im2\n",
    "    sq_diffs = diffs * diffs\n",
    "    \n",
    "    mask = np.zeros((2*K+1,2*K+1)) + 1\n",
    "    \n",
    "    return convolve(sq_diffs, mask, mode='constant')\n",
    "\n",
    "# Fastest way I know to write it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 13.** Implementa la función ``D = ssd_volume(im1, im2, disps, K)`` que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de la imagen ``im1`` y la imagen ``im2`` desplazada\n",
    "horizontalmente. El parámetro ``disps`` debe ser una lista\n",
    "de valores indicando las disparidades que se usarán para desplazar la imagen ``im2``. Por ejemplo, si ``disps`` es\n",
    "``np.arange(-3,2)``, se llamará 5 veces a ``localssd`` para la\n",
    "imagen 1 y la imagen 2 desplazada −3 , −2 , −1 , 0 y 1 píxeles\n",
    "en sentido horizontal. K es el parámetro que indica el radio\n",
    "de las ventanas usado por localssd.\n",
    "\n",
    "El valor devuelto D será un array de tamaño $M × N × L$,\n",
    "donde L es el número de disparidades indicadas por ``disps``,\n",
    "``L = len(disps)`` (es decir, el número de veces que se ha\n",
    "llamado a ``localssd``); M y N son, respectivamente, el\n",
    "número de filas y de columnas de las imágenes de entrada.\n",
    "El elemento ``D[y,x,l]`` debe ser la SSD entre la ventana\n",
    "centrada en ``im1[y,x]`` y la ventana centrada en ``im2[y,x + disps[l]]``.\n",
    "\n",
    "``D[y,x,l]`` debe ser muy grande para aquellos valores en\n",
    "los que ``im2[y,x + disps[l]]`` no esté definido, es decir,\n",
    "el índice``(y,x+disps[l])`` se sale de la imagen 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_img(img, l):\n",
    "    \n",
    "    h,w = img.shape\n",
    "    \n",
    "    if l > 0:\n",
    "        return np.hstack((img[:,l:],np.zeros((h,l))))\n",
    "    else:\n",
    "        return np.hstack((np.zeros((h,-l)),img[:,:w+l]))\n",
    "    # inf instead of 0, or is that too big?\n",
    "\n",
    "def ssd_volume(im1, im2, disps, K):\n",
    "    \"\"\"\n",
    "    Calcula el volumen de disparidades SSD\n",
    "    \"\"\"\n",
    "    \n",
    "    l_m_n = np.array([localssd(im1,shift_img(im2,l),K) for l in disps])\n",
    "    \n",
    "    m_n_l = np.moveaxis(l_m_n,0,2)\n",
    "    \n",
    "    return m_n_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 14.** El conjunto de disparidades ``disps`` debe ser lo más pequeño posible, para mejorar el rendimiento de la optimización. Determina un procedimiento para estimar manualmente el conjunto de disparidades posibles y aplícalo a las imágenes O1 y O2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** No entiendo muy bien que se pretende con lo de determinar un procedimiento para estimar manualmente el conjunto de disparidades posibles. Por ahora voy a usar misc.askpoints() y buscar a ojo la disparidad mínima y máxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2 = misc.askpoints(O1,O2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148.30040323, 165.86491935],\n",
       "       [-13.1733871 ,  -8.78225806],\n",
       "       [  0.        ,   0.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1-p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "disps = np.arange( 100, 200)  #! 125,205 # obfuscate 120,210?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica la función ``ssd_volume`` al par de imágenes O1 y O2\n",
    "con las disparidades estimadas en el ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656, 495, 100)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = ssd_volume(O2, O1, disps, 5)\n",
    "\n",
    "# to speed-up the optimization ahead, discard the par of the image showing only background\n",
    "\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Estimación de la disparidad sin regularizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz D calculada en el ejercicio anterior proporciona\n",
    "los costes unitarios $D_i$ de una función de energía sin regularización de la forma $$E(x) = \\sum_{i} D_i(x_i),$$\n",
    "donde $D_i(l)$ viene dado por $D[y,x,l]$, suponiendo que\n",
    "el píxel $i$ tenga coordenadas $(x, y)$. Las variables \n",
    "$x = (x_1 ,\\ldots, x_{NM})$ indican las etiquetas de cada uno de los\n",
    "píxeles. En este caso, las etiquetas son los índices del\n",
    "array ``disps``, que a su vez son las disparidades horizontales.\n",
    "Por eso, a partir de aquí se hablará indistintamente de\n",
    "etiquetas y disparidades. Sólo es necesario recordar que la\n",
    "etiqueta $l$ está asociada a la disparidad ``disps[l]``.\n",
    "\n",
    "\n",
    "Minimizando la energía $x = \\arg\\min_x E(x)$,\n",
    "se obtiene un vector de etiquetas óptimo $x^*$ que indica, para\n",
    "cada píxel, cuál es su disparidad horizontal entre las dos\n",
    "imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 15.** Minimiza $E(x)$ y muestra las disparidades resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ... TODO ... #! D.arigmin(2)\n",
    "ppl.imshow(res,cmap='gray')\n",
    "ppl.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Estimación de la disparidad regularizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El etiquetado usando exclusivamente términos unitarios\n",
    "es muy sensible al ruido y propenso a que aparezcan zonas\n",
    "de píxeles cercanos con mucha variación en las etiquetas.\n",
    "Esto es especialmente notable en zonas planas (es decir, sin\n",
    "textura) de las imágenes originales, donde no hay suficiente\n",
    "información para establecer una correspondencia basándose\n",
    "exclusivamente en la apariencia visual de ventanas pequeñas. Por eso es necesario incluir un término de suavizado\n",
    "o regularización en la función de energía. Los tipos de\n",
    "saltos de etiquetas que aparecerán en el resultado final\n",
    "dependerán de cómo sea ese término de suavizado.\n",
    "\n",
    "La función de energía que utilizaremos para calcular\n",
    "las disparidades en la práctica será el resultado de añadir\n",
    "a la expresión (6) un término que penalice los cambios de\n",
    "disparidad en los píxeles vecinos: $$E_r(x) = \\sum_{i} D_i(x_i) + \\lambda\\sum_{ij} \\min(k,|x_i-x_j|).$$ Siendo $j$ los índices de los píxeles vecinos del $i$ en la imagen.\n",
    "La solución al problema de la correspondencia vendrá dado\n",
    "por el conjunto de etiquetas (disparidades) de los píxeles de\n",
    "la imagen que minimicen $E_r(x)$.\n",
    "\n",
    "En [Yuri Boykov, Olga Veksler, and Ramin Zabih. \"Fast approximate\n",
    "energy minimization via graph cuts\". *IEEE Transactions on Pattern\n",
    "Analysis and Machine Intelligence*, 23:1222–1239, 2001.] se presentan métodos para resolver algunos problemas de optimización con varias etiquetas empleando\n",
    "algoritmos de cortes de grafos. Es recomendable repasar las\n",
    "secciones 5 y 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 16.** Escribe la función ``find_corresp_aexpansion(D, initLabels, lmb, maxV)``,\n",
    "que recie un volumen ssd, ``D``, un conjunto inicial de\n",
    "etiquetas, ``initLabels``, que puede ser el obtenido en el\n",
    "ejercicio 5, el valor de la constante $\\lambda$, y el valor máximo\n",
    "de la función de coste $|x_i − x_j|$, que tendrás que establecer empíricamente. El resultado de esta función serán las\n",
    "etiquetas que minimizan $E_r(x)$. Para ello debes utilizar la función ``maxflow.fastmin.aexpansion_grid(D, V, max_cycles=None, labels=None)`` del paquete\n",
    "*PyMaxFlow*, que resuelve el problema anterior mediante un\n",
    "algoritmo de cortes de grafos empleando una $\\alpha$-expansión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corresp_aexpansion(D, initialLabels, lmb, maxV):\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama a esta función y muestra una figura con las etiquetas que resulten de la minimización de la energía para el volumen ssd ``D`` (este proceso puede durar varios minutos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = find_corresp_aexpansion(D, res, ... , ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.imshow(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de etiquetas óptimas X obtenida de la minimización de la función de energía puede transformarse en\n",
    "la matriz de disparidades S indexando en cada una de sus\n",
    "celdas el array de disparidades disps ``S = disps[X]``.\n",
    "Ahora, el píxel de coordenadas (x, y) de la primera imagen\n",
    "rectificada tendrá su correspondencia en el píxel de coordenadas (x + S [y, x], y) de la segunda imagen rectificada.\n",
    "\n",
    "El siguiente ejercicio usa la matriz de disparidades para\n",
    "establecer automáticamente las correspondencias entre un\n",
    "par de imágenes sin rectificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 15.** Implementa la función\n",
    "``plot_correspondences(image1, image2, S, H1,H2)``\n",
    "que, dado un par de imágenes sin rectificar, la matriz de\n",
    "disparidades entre las imágenes rectificadas y las homogra-\n",
    "fías que llevan de las imágenes sin rectificar a las imágenes\n",
    "rectificadas, pida al usuario puntos en la primera imagen y\n",
    "dibuje sus correspondencias en la segunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correspondences(image1, image2, S, H1, H2):\n",
    "    \"\"\"\n",
    "    Ask for points in the first image and plot their correspondences in\n",
    "    the second image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1, image2 : array_like\n",
    "        The images (before rectification)\n",
    "    S : array_like\n",
    "        The matrix of disparities.\n",
    "    H1, H2 : array_like\n",
    "        The homographies which rectify both images.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.c_[np.array(point), 1].T\n",
    "        ax1.plot(point[0,:], point[1,:], '.r')\n",
    "        \n",
    "        # TODO: Determine the correspondence of 'point' in the second image.\n",
    "        # perhaps you have to swap the image co-ordinates.\n",
    "        \n",
    "        \n",
    "        # TODO: Plot the correspondence with ax2.plot.\n",
    "        \n",
    "\n",
    "        ax2.plot(... ,... ,'r.')\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ... TODO ...\n",
    "plot_correspondences(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
